{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85366b61-fa37-455b-bc03-a568164eb355",
   "metadata": {},
   "source": [
    "#LIst of Libraries:\n",
    "https://www.ogbmagnitka.ru/info/links.html  \n",
    "https://globalistika.ru/nauchnie-i-elecronnie-biblioteki  \n",
    "https://uralgufk.ru/news/14-elektronnyh-bibliotek-gde-mozhno-brat-knigi-besplatno-i-legalno  \n",
    "https://www.shpl.ru/readers/helpful_links/free_ebooks/  \n",
    "https://sysblok.ru/digest/5-rossijskih-bibliotek-s-bogatymi-cifrovymi-kollekcijami/ \n",
    "\n",
    "АГИТАЦИОННЫЙ МАТЕРИАЛ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41a90939-e244-48db-b1d3-3e7857870b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_Prlib Initial considerations add-on.ipynb\n",
      "0_SCRAP Prlib Book names.ipynb\n",
      "1_PrLib ASYNCIO FULL.ipynb\n",
      "API Internet ARchive.ipynb\n",
      "Books_copy (from website copy the links).ahk\n",
      "Get_number_of_pages_from_urls.py\n",
      "history_Archive.txt\n",
      "Images_Count_8-6-25.csv\n",
      "Monitoring Archive org.py\n",
      "Monitoring Archive-org.png\n",
      "result_data_pages_process_csv.py\n",
      "result_data_pages_process_txt.py\n",
      "Update excel + dATA PAGES SCRAP.ipynb\n",
      "Update_Excel_from_Archive.py\n",
      "Update_sent_to_download_folder.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "BOOK_DIR=\"PRLIB\"\n",
    "path=os.path.join(BOOK_DIR)\n",
    "lst = os.listdir(path) # your directory path\n",
    "            #check on not zero:\n",
    "count_images=0\n",
    "for file in lst:\n",
    "    if os.path.getsize(os.path.join(path,file))!=0:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0d29d1-0103-4d27-9b14-cb5173ff2d36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Overview of GPIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01cabc57-2609-410b-9f9d-c31f30d8628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "url=\"http://elib.shpl.ru/ru/nodes/98765-16-marta-1912-g-89007-188-locale-nil-1912\"\n",
    "database=\"FULL_BOOKS_GPIB.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c7c7da3-3ec3-40c3-8285-0fee534d0b1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'creator': '', 'language': 'Russian', 'mediatype': 'texts', 'title': 'Россия. Департамент полиции. Губернаторам, градоначальникам, Варшавскому обер-полициймейстеру... [Списки разыскиваемых лиц]. – Б.м., [1912]. 16 марта 1912 г., 89007/188. – [1912].', 'Full_title': 'Россия. Департамент полиции. Губернаторам, градоначальникам, Варшавскому обер-полициймейстеру... [Списки разыскиваемых лиц]. – Б.м., [1912]. 16 марта 1912 г., 89007/188. – [1912].', 'description': 'Россия. Департамент полиции. Губернаторам, градоначальникам, Варшавскому обер-полициймейстеру, начальникам жандармских и железнодорожных полицейских управлений, охранных отделений и жандармским офицерам на пограничных пунктах. [Списки разыскиваемых лиц] / М-во внутр дел, Департамент полиции по 8 делопроизводству. – Б.м., [1912]. - Без тит. л. и обл., описано по 1-й с. текст . – Секретно. Циркулярно . 16 марта 1912 г., 89007/188 : [Списки А1, А2, Б1, Б2, В и Г разыскиваемых лиц и 86 экземпляров розыскных карт]. – [1912]. – 14 с.: портр.', 'subject': ['\"Жандармская\" коллекция'], 'date': '1912', 'Source_url': 'http://elib.shpl.ru/ru/nodes/98765-16-marta-1912-g-89007-188-locale-nil-1912'}\n"
     ]
    }
   ],
   "source": [
    "with open(database,\"r\",encoding=\"utf-8-sig\") as base:\n",
    "    csvFile=csv.reader(base,delimiter=\";\")\n",
    "    for row in csvFile:\n",
    "        if row[2]==url:\n",
    "            #get all the data:\n",
    "            if row[0]!=\"\":\n",
    "                date=row[0]\n",
    "            else:\n",
    "                date=\"\"\n",
    "            if row[4]!=\"\":\n",
    "                description=row[4].replace('\\xa0', ' ')\n",
    "            else:\n",
    "                description=row[1].replace('\\xa0', ' ')\n",
    "            if row[7]!=\"\":\n",
    "                author_=row[7].replace('\\xa0', ' ')\n",
    "            else:\n",
    "                author_=\"\"\n",
    "            if row[1]!=\"\":\n",
    "                title=row[1][:230].replace('\\xa0', ' ')\n",
    "                full_title=row[1].replace('\\xa0', ' ')\n",
    "            else:\n",
    "                title=row[8][:230].replace('\\xa0', ' ')\n",
    "                full_title=row[8].replace('\\xa0', ' ')\n",
    "            if row[6]!=\"\":\n",
    "                res=re.split(r'\\(\\d+\\)',row[6])\n",
    "                subjects=[i.replace('\\xa0', ' ').strip() for i in res]\n",
    "            else:\n",
    "                subjects=\"\"\n",
    "            #language detection:\n",
    "            try:\n",
    "                lang=detect(title)\n",
    "            except:\n",
    "                lang=''\n",
    "            dict_lang={\"de\":\"German\", \"en\":\"English\"}\n",
    "            if lang in list(dict_lang.keys()):\n",
    "                language=dict_lang[lang]\n",
    "            else:\n",
    "                language=\"Russian\"\n",
    "print({\"creator\" : author_,\n",
    "        \"language\" : language,\n",
    "        \"mediatype\" : \"texts\",\n",
    "        \"title\" : title,\n",
    "        \"Full_title\": full_title,\n",
    "        \"description\":   description,\n",
    "        \"subject\":subjects,\n",
    "        \"date\":date,\n",
    "        \"Source_url\": url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8deae345-ac87-4c8a-9493-b84cf1e4d27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'Год издания'), (1, 'title'), (2, 'url'), (3, 'Availability'), (4, 'Библиографическое описание'), (5, 'Тип издания'), (6, 'Коллекции'), (7, 'Автор'), (8, 'Заглавие'), (9, 'Number_of_Images'), (10, 'Images')]\n"
     ]
    }
   ],
   "source": [
    "with open(database,\"r\",encoding=\"utf-8-sig\") as base:\n",
    "    csvFile=csv.reader(base,delimiter=\";\")\n",
    "    url=\"http://elib.shpl.ru/ru/nodes/49403-1911-1912-gg-kn-1-1913\"\n",
    "    for row in csvFile:\n",
    "        print([(k,v) for k,v in enumerate(row)])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a3b407c-b7c8-40f4-91b7-6ecd9728a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf40b3a-6cf2-4fff-87e9-f1e255b2dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url=\"http://elib.shpl.ru/ru/nodes/49403-1911-1912-gg-kn-1-1913\"\n",
    "database=\"FULL_BOOKS_GPIB.csv\"\n",
    "with open(database,\"r\",encoding=\"utf-8-sig\") as base:\n",
    "    csvFile=csv.reader(base,delimiter=\";\")\n",
    "    for row in csvFile:\n",
    "        if row[2]==url:\n",
    "            pages=row[10].split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7d09476-814c-4c13-983e-28074538a6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'elib.shpl.ru'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib\n",
    "urllib.parse.urlsplit(url).netloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc518ac7-0704-4045-8e17-c0051d0f1056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb73f0e-25a3-45c6-926b-96cdd8793ea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d35a15f-976b-457d-af43-893d8b301549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d39ec064-41a9-4fd9-9236-8d99164f0d31",
   "metadata": {},
   "source": [
    "### Big overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d848afaf-a915-430a-880a-9475f3e0b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls_origin=['http://elib.shpl.ru/ru/indexes/values/111532?per_page=200&page={}'.format(i) for i in range(34,146)]\n",
    "with open(\"GPIB_Agitation.txt\",\"r\") as file:\n",
    "    urls_origin=file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "540d9a7d-7ffa-4aa6-a472-583e06409213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "urls=[]\n",
    "titles=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c30283de-0fe5-42df-9861-9aed13b6cbec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "count=0\n",
    "for url_origin in urls_origin:\n",
    "    #resp=requests.get(url_origin, headers=headers_pr)\n",
    "    #html=resp.text\n",
    "    driver.get(url_origin)\n",
    "    wait = WebDriverWait(driver, 60)\n",
    "    element = wait.until(EC.presence_of_element_located((By.CLASS_NAME, 'nodes-view')))\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    all_items=soup.find_all(class_=\"nodes-grid\")[0].find_all(\"li\")\n",
    "    for item in all_items:\n",
    "        try:\n",
    "            url='http://elib.shpl.ru'+item.a[\"href\"]\n",
    "            title=item.a.find(\"img\")[\"alt\"]\n",
    "        except:\n",
    "            continue\n",
    "        urls.append(url)\n",
    "        titles.append(title)\n",
    "    print(count)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "97fb1b52-115f-43f5-8f22-116abd4f6dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[[titles[i],urls[i]] for i in range(len(urls))]\n",
    "data.insert(0,[\"title\",\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f166c735-1235-488d-80d1-3d3d993bf2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('Books_GPIB.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(data)\n",
    "\n",
    "\"\"\"\n",
    "with open('Books_GPIB.csv', 'r', encoding='utf-8') as f:\n",
    "    writer = csv.reader(f)\n",
    "    data=list(writer)\n",
    "\n",
    "data.insert(0,[\"title\",\"url\"])\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cdfb03-45fd-47be-a043-70c6428d3d59",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# DOwnloading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4bb8ffd8-0e8a-4b7a-b4ed-fee0041d3afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def download_image(url,session,idx,sem1):\n",
    "    async with sem1:\n",
    "        async with session.get(url) as response:\n",
    "            if response.ok:  \n",
    "                with open(\"images\\\\\"+str(idx)+\".jpg\",\"wb\") as file1:              \n",
    "                    file1.write(await response.read()) \n",
    "async def create_download(pages):\n",
    "    sem1 = asyncio.Semaphore(10)\n",
    "    async with ClientSession(timeout=ClientTimeout(total=30),headers=hedaders_1) as session:\n",
    "        tasks = [asyncio.create_task(download_image(f'http://elib.shpl.ru//pages/{page[\"id\"]}/zooms/8',session,idx,sem1)) for idx, page in enumerate(pages)]\n",
    "        results = await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5b3e345a-086f-412f-b28d-0ae23fc5ff3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.611894845962524\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "eshplDl('http://elib.shpl.ru/ru/nodes/95737-i-vedet-etu-armiyu-stalin-locale-nil-m-1934')\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "860d4d86-1bb6-41fe-90f4-a94dc0873fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import nest_asyncio\n",
    "def eshplDl(url):\n",
    "    ext = '.jpg'\n",
    "    quality = 8\n",
    "    domain = urllib.parse.urlsplit(url).netloc\n",
    "    html_text = requests.get(url,headers=hedaders_1).text\n",
    "    \n",
    "    #print(html_text)\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    #title = select_one_text_optional(soup, 'title') or md5_hex(url)\n",
    "    #title = safe_file_name(title)\n",
    "    for script in soup.find_all('script'):   \n",
    "        st = str(script)      \n",
    "        if 'initDocview' in st:\n",
    "            book_json = json.loads(st[st.find('{\"'): st.find(')')])\n",
    "    pages = book_json['pages']\n",
    "    nest_asyncio.apply()\n",
    "    asyncio.run(create_download(pages))\n",
    "   \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "be5dcf77-e9f5-4f53-ace3-c2a9a4470c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "hedaders_1={\n",
    "'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "'Accept-Encoding': 'gzip, deflate',\n",
    "'Accept-Language': 'en-GB,en-US;q=0.9,en;q=0.8,ru;q=0.7',\n",
    "'Cache-Control': 'max-age=0',\n",
    "'Connection': 'keep-alive',\n",
    "'Cookie': 'ahoy_visitor=e89e88c5-5cfe-4cbc-99d7-db554c5b590f; ahoy_visit=ea23e526-abc4-441e-82bd-b12b87ea51bd; _platform_session=u%2Fw%2B02eobjNyxpdUXwmMmPLpVAfdnxnFFY2X9CbZFBv5%2FHGveIt3kQBSWHk05oqxl%2B7%2BwybGXDhBxJXnvHtapmTeex%2Fo3lMDvJFhkVFmnzg4jXXlH9DF9TzkatrN2b7D0EQ%2BM4Y82mhm6pq8TZZhHk08d6fFyF4d6aEN0YSSnlMwLsfVVBWOxU5B7lq9e0aMd7SljZnFHEIRSI2oWS3H6yJ5RMWCrJQIWLhFvYduN0NHV524iwU8FMqREOi9BYyaAucrFQTEp4r0qtJ5yOapyvCHQPZ49I9jPgE19NYVciIm915EGHq4eWwEL4NOx6hEhdWEs1020utyzCGW1zWxsQWSMlyG5%2BU632erUjH1TtngXUBd9JwSUAT1UNuBkRU6BkAYd6QRqo8bcxqavOR22W5mZDCvQzHySyqbkqmj2EFPZ2OTAkPcUicptY0npNSDejtR9thyCeD1JKhynjH6r3Kx1kCX7iqUsrcaPpQGDBnahDVCIXyfCYiMvFUFz9jd1AI5Bc4HvF0PQb7zEEhxWjPoMrlG7rFSiZUcUoNXyVYWbV4lucdgb%2FODYAvwsfFHy0s48Ra%2Be334VD%2FaQD%2FjbJkBhzVv%2FWaakoITWxXZnPmhHVkf5RClAk5XKOEAV9qLQk%2BAgwE%2BMTYmMnp4rwiPIGjtUxsVxRRqU%2Bol7ILFOlLJvyHO2DFqLU90EdnIo6O3FkK4s8EzmjaZw1Qk6ScHkAbjO69Rw5VzKiJuYIxpz9r5UHknqrPu2CU52HdUWQRnGK2k9%2FyJWwrupD4%2BWSEcCwHognAhLZPlYw%3D%3D--UPGzuhyp2iLY48RW--IjLVYayGjnr7AOtz9T6bug%3D%3D' ,\n",
    "'Host': 'elib.shpl.ru',\n",
    "'If-None-Match': 'W/\"64989674aff36611149027327f12df67\"',\n",
    "'Upgrade-Insecure-Requests': '1',\n",
    "'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36',\n",
    "'dnt': '1',\n",
    "'sec-gpc': '1'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb23122e-2210-48d6-a394-57ae7f6c303c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d1bb268-5aee-4aa9-a967-480005fc6bd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbs4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBrowser\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpause \u001b[38;5;241m=\u001b[39m pause\n",
      "Cell \u001b[1;32mIn[19], line 25\u001b[0m, in \u001b[0;36mBrowser\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpause \u001b[38;5;241m=\u001b[39m pause\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m, headers: Dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, content_type: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     26\u001b[0m     headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_headers(headers)\n\u001b[0;32m     27\u001b[0m     log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mЗапрашиваю GET \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dict' is not defined"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import urllib.parse\n",
    "import asyncio\n",
    "from aiohttp import ClientSession,TCPConnector, ClientTimeout\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import img2pdf\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "\n",
    "\n",
    "class Browser:\n",
    "\n",
    "    def __init__(self, pause: float):\n",
    "        self.pause = pause\n",
    "\n",
    "    \n",
    "    def get_text(self, url: str, headers: Dict = None, content_type: str = None):\n",
    "        headers = self._prepare_headers(headers)\n",
    "        log.info(f'Запрашиваю GET {url}')\n",
    "        log.info(f'Заголовки: {headers}')\n",
    "        response = requests.get(url, headers=headers)\n",
    "        log.info(f'Ответ: {response.status_code} {response.reason}')\n",
    "        log.info(f'Заголовки: {response.headers}')\n",
    "        self._validate_response(response, url, content_type)\n",
    "        return response.text\n",
    "\n",
    " \n",
    "    def post_text(self, url: str, headers: Dict = None, data: Dict = None, content_type: str = None):\n",
    "        headers = self._prepare_headers(headers)\n",
    "        log.info(f'Запрашиваю POST {url}')\n",
    "        log.info(f'Заголовки: {headers}')\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "        log.info(f'Ответ: {response.status_code} {response.reason}')\n",
    "        log.info(f'Заголовки: {response.headers}')\n",
    "        self._validate_response(response, url, content_type)\n",
    "        return response.text\n",
    "\n",
    "\n",
    "    def download(self, url: str,\n",
    "                 fpath: str,\n",
    "                 headers: Dict = None,\n",
    "                 content_type: Union[str, Pattern] = None,\n",
    "                 skip_if_file_exists=False):\n",
    "        global last_time_connected\n",
    "        progress(f' - Скачиваю {url}')\n",
    "        if skip_if_file_exists and os.path.exists(fpath) and os.stat(fpath).st_size > 0:\n",
    "            log.info(f'Пропускаю скачанный файл: {fpath}')\n",
    "            last_time_connected = None\n",
    "            return\n",
    "        headers = self._prepare_headers(headers)\n",
    "        log.info(f'Запрашиваю GET {url}')\n",
    "        log.info(f'Заголовки: {headers}')\n",
    "        response = requests.get(url, stream=True, headers=headers)\n",
    "        log.info(f'Ответ: {response.status_code} {response.reason}')\n",
    "        log.info(f'Заголовки: {response.headers}')\n",
    "        self._validate_response(response, url, content_type)\n",
    "        mkdirs_for_regular_file(fpath)\n",
    "        with open(fpath, 'wb') as fd:\n",
    "            shutil.copyfileobj(response.raw, fd)\n",
    "        length = os.stat(fpath).st_size\n",
    "        ptext(f' - Сохранено в файл {fpath} ({length} байт)')\n",
    "\n",
    "    def _prepare_headers(self, additional_headers: Dict):\n",
    "        headers = additional_headers if additional_headers else {}\n",
    "        headers.update({'User-Agent': random.choice(user_agents)})\n",
    "        return headers\n",
    "\n",
    "    def _validate_response(self, response: Response, url, expected_ct: Union[str, Pattern]):\n",
    "        if not response.ok:\n",
    "            raise Exception(f'Не удалось скачать файл {url} - {response.status_code} {response.reason}')\n",
    "        if expected_ct:\n",
    "            actual_ct: str = response.headers.get('content-type')\n",
    "            if actual_ct:\n",
    "                if isinstance(expected_ct, Pattern):\n",
    "                    if not expected_ct.match(actual_ct):\n",
    "                        perror(f'Некорректный content-type {actual_ct} по адресу {url}')\n",
    "                else:\n",
    "                    if actual_ct != expected_ct:\n",
    "                        perror(f'Некорректный content-type {actual_ct} по адресу {url}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
